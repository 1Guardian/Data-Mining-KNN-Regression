# Data-Mining-KNN-Regression

This project required that you obtain N = 100 _iid_ samples uniformly and randomly between 1 and 10, and then create corresponding y values by taking the natural logarithm of _x_ plus a random and uniform guassian noise. Once that was complete, then K-NN regression was used to obtain _y-cap_ values at x-values of 1, 3, 5, 7 and 9 for three different schemes: where all K neighbors contribute equally, where each neigher has an influence that is inveresly proportional to the distance from each point, and where each point contributes as given by 3^(-.5*(d^2)) where d is distance.

The project is in a pdf version of the ipynb for easier viewing by anyone
